package resource

import (
	"context"
	"encoding/csv"
	"fmt"
	"io"
	"os"
	"strconv"
	"strings"
	"sync"
)

// CSVSource CSVæ–‡ä»¶æ•°æ®æºå®ç?é‡‡ç”¨DuckDBä¼˜åŒ–æŠ€æœ?
type CSVSource struct {
	config      *DataSourceConfig
	connected   bool
	writable    bool // CSVæ–‡ä»¶é»˜è®¤åªè¯»
	mu          sync.RWMutex
	filePath    string
	columns     []ColumnInfo
	delimiter   rune
	header      bool
	// å¹¶è¡Œè¯»å–é…ç½®
	chunkSize   int64
	workers     int
	// å†…å­˜æ˜ å°„æ”¯æŒ
	useMmap     bool
}

// CSVFactory CSVæ•°æ®æºå·¥å?
type CSVFactory struct{}

// NewCSVFactory åˆ›å»ºCSVæ•°æ®æºå·¥å?
func NewCSVFactory() *CSVFactory {
	return &CSVFactory{}
}

// GetType å®ç°DataSourceFactoryæ¥å£
func (f *CSVFactory) GetType() DataSourceType {
	return DataSourceTypeCSV
}

// Create å®ç°DataSourceFactoryæ¥å£
func (f *CSVFactory) Create(config *DataSourceConfig) (DataSource, error) {
	if config.Options == nil {
		config.Options = make(map[string]interface{})
	}
	
	// é»˜è®¤é…ç½®
	delimiter := ','
	if d, ok := config.Options["delimiter"]; ok {
		if str, ok := d.(string); ok && len(str) > 0 {
			delimiter = rune(str[0])
		}
	}
	
	header := true
	if h, ok := config.Options["header"]; ok {
		if b, ok := h.(bool); ok {
			header = b
		}
	}
	
	chunkSize := int64(1 << 20) // 1MB
	if cs, ok := config.Options["chunk_size"]; ok {
		if num, ok := cs.(int64); ok && num > 0 {
			chunkSize = num
		}
	}
	
	workers := 4
	if w, ok := config.Options["workers"]; ok {
		if num, ok := w.(int); ok && num > 0 && num <= 32 {
			workers = num
		}
	}
	
	useMmap := true
	if m, ok := config.Options["mmap"]; ok {
		if b, ok := m.(bool); ok {
			useMmap = b
		}
	}
	
	return &CSVSource{
		config:    config,
		writable:   false, // CSVæ–‡ä»¶é»˜è®¤åªè¯»
		filePath:  config.Name,
		delimiter: delimiter,
		header:    header,
		chunkSize: chunkSize,
		workers:   workers,
		useMmap:   useMmap,
	}, nil
}

// Connect è¿æ¥æ•°æ®æº?
func (s *CSVSource) Connect(ctx context.Context) error {
	s.mu.Lock()
	defer s.mu.Unlock()
	
	// æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ?
	if _, err := os.Stat(s.filePath); err != nil {
		return fmt.Errorf("CSV file not found: %s", s.filePath)
	}
	
	// æ¨æ–­åˆ—ä¿¡æ?
	if err := s.inferSchema(ctx); err != nil {
		return fmt.Errorf("failed to infer schema: %w", err)
	}
	
	s.connected = true
	return nil
}

// Close å…³é—­è¿æ¥
func (s *CSVSource) Close(ctx context.Context) error {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.connected = false
	return nil
}

// IsConnected æ£€æŸ¥æ˜¯å¦å·²è¿æ¥
func (s *CSVSource) IsConnected() bool {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return s.connected
}

// GetConfig è·å–æ•°æ®æºé…ç½?
func (s *CSVSource) GetConfig() *DataSourceConfig {
	return s.config
}

// IsWritable æ£€æŸ¥æ˜¯å¦å¯å†?
func (s *CSVSource) IsWritable() bool {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return s.writable
}

// GetTables è·å–æ‰€æœ‰è¡¨ (CSVæ–‡ä»¶æœ¬èº«ä½œä¸ºä¸€ä¸ªè¡¨)
func (s *CSVSource) GetTables(ctx context.Context) ([]string, error) {
	if !s.IsConnected() {
		return nil, fmt.Errorf("not connected")
	}
	return []string{"csv_data"}, nil
}

// GetTableInfo è·å–è¡¨ä¿¡æ?
func (s *CSVSource) GetTableInfo(ctx context.Context, tableName string) (*TableInfo, error) {
	if !s.IsConnected() {
		return nil, fmt.Errorf("not connected")
	}
	
	if tableName != "csv_data" {
		return nil, fmt.Errorf("table %s not found", tableName)
	}
	
	return &TableInfo{
		Name:    "csv_data",
		Columns: s.columns,
	}, nil
}

// Query æŸ¥è¯¢æ•°æ® - å®ç°å¹¶è¡Œæµå¼è¯»å–
func (s *CSVSource) Query(ctx context.Context, tableName string, options *QueryOptions) (*QueryResult, error) {
	if !s.IsConnected() {
		return nil, fmt.Errorf("not connected")
	}
	
	if tableName != "csv_data" {
		return nil, fmt.Errorf("table %s not found", tableName)
	}
	
	// åº”ç”¨è¿‡æ»¤ä¸‹æ¨ - åœ¨è¯»å–é˜¶æ®µè¿‡æ»?
	// åˆ—è£å‰?- åªè¯»å–éœ€è¦çš„åˆ?
	neededColumns := s.getNeededColumns(options)
	
	// å¹¶è¡Œè¯»å–æ•°æ®
	rows, err := s.readParallel(ctx, neededColumns, options)
	if err != nil {
		return nil, err
	}
	
	// åº”ç”¨è¿‡æ»¤å™?(å¦‚æœè¿˜æœ‰æœªä¸‹æ¨çš„æ¡ä»¶)
	filteredRows := s.applyFilters(rows, options)
	
	// åº”ç”¨æ’åº
	sortedRows := s.applyOrder(filteredRows, options)
	
	// åº”ç”¨åˆ†é¡µ
	total := int64(len(sortedRows))
	pagedRows := s.applyPagination(sortedRows, options)
	
	// æ„å»ºåˆ—ä¿¡æ?
	columns := s.columns
	if len(neededColumns) > 0 {
		columns = s.filterColumns(neededColumns)
	}
	
	return &QueryResult{
		Columns: columns,
		Rows:    pagedRows,
		Total:   total,
	}, nil
}

// Insert æ’å…¥æ•°æ®
func (s *CSVSource) Insert(ctx context.Context, tableName string, rows []Row, options *InsertOptions) (int64, error) {
	return 0, fmt.Errorf("CSV data source is read-only")
}

// Update æ›´æ–°æ•°æ®
func (s *CSVSource) Update(ctx context.Context, tableName string, filters []Filter, updates Row, options *UpdateOptions) (int64, error) {
	return 0, fmt.Errorf("CSV data source is read-only")
}

// Delete åˆ é™¤æ•°æ®
func (s *CSVSource) Delete(ctx context.Context, tableName string, filters []Filter, options *DeleteOptions) (int64, error) {
	return 0, fmt.Errorf("CSV data source is read-only")
}

// CreateTable åˆ›å»ºè¡?
func (s *CSVSource) CreateTable(ctx context.Context, tableInfo *TableInfo) error {
	return fmt.Errorf("CSV data source is read-only")
}

// DropTable åˆ é™¤è¡?
func (s *CSVSource) DropTable(ctx context.Context, tableName string) error {
	return fmt.Errorf("CSV data source is read-only")
}

// TruncateTable æ¸…ç©ºè¡?
func (s *CSVSource) TruncateTable(ctx context.Context, tableName string) error {
	return fmt.Errorf("CSV data source is read-only")
}

// Execute æ‰§è¡Œè‡ªå®šä¹‰SQLè¯­å¥
func (s *CSVSource) Execute(ctx context.Context, sql string) (*QueryResult, error) {
	return nil, fmt.Errorf("CSV data source does not support SQL execution")
}

// inferSchema æ¨æ–­CSVæ–‡ä»¶çš„åˆ—ä¿¡æ¯
func (s *CSVSource) inferSchema(ctx context.Context) error {
	file, err := os.Open(s.filePath)
	if err != nil {
		return err
	}
	defer file.Close()
	
	reader := csv.NewReader(file)
	reader.Comma = s.delimiter
	
	// è¯»å–å¤´éƒ¨
	headers, err := reader.Read()
	if err != nil {
		return err
	}
	
	// é‡‡æ ·å‰?000è¡Œæ¨æ–­ç±»å?
	sampleSize := 1000
	samples := make([][]string, 0, sampleSize)
	for i := 0; i < sampleSize; i++ {
		row, err := reader.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			continue
		}
		samples = append(samples, row)
	}
	
	// æ¨æ–­æ¯åˆ—çš„ç±»å?
	s.columns = make([]ColumnInfo, len(headers))
	for i, header := range headers {
		colType := s.inferColumnType(i, samples)
		s.columns[i] = ColumnInfo{
			Name:     strings.TrimSpace(header),
			Type:     colType,
			Nullable: true,
			Primary:  false,
		}
	}
	
	return nil
}

// inferColumnType æ¨æ–­åˆ—ç±»å?
func (s *CSVSource) inferColumnType(colIndex int, samples [][]string) string {
	if len(samples) == 0 {
		return "VARCHAR"
	}
	
	typeCounts := map[string]int{
		"INTEGER":  0,
		"FLOAT":    0,
		"BOOLEAN":  0,
		"VARCHAR":  0,
	}
	
	for _, row := range samples {
		if colIndex >= len(row) {
			continue
		}
		value := strings.TrimSpace(row[colIndex])
		if value == "" {
			continue
		}
		
		colType := s.detectType(value)
		typeCounts[colType]++
	}
	
	// é€‰æ‹©æœ€å¸¸è§çš„ç±»å?
	maxCount := 0
	bestType := "VARCHAR"
	for t, count := range typeCounts {
		if count > maxCount {
			maxCount = count
			bestType = t
		}
	}
	
	return bestType
}

// detectType æ£€æµ‹å€¼çš„ç±»å‹
func (s *CSVSource) detectType(value string) string {
	// å°è¯•è§£æä¸ºå¸ƒå°”å€?
	if strings.EqualFold(value, "true") || strings.EqualFold(value, "false") {
		return "BOOLEAN"
	}
	
	// å°è¯•è§£æä¸ºæ•´æ•?
	if _, err := strconv.ParseInt(value, 10, 64); err == nil {
		return "INTEGER"
	}
	
	// å°è¯•è§£æä¸ºæµ®ç‚¹æ•°
	if _, err := strconv.ParseFloat(value, 64); err == nil {
		return "FLOAT"
	}
	
	return "VARCHAR"
}

// readParallel å¹¶è¡Œè¯»å–CSVæ–‡ä»¶
func (s *CSVSource) readParallel(ctx context.Context, neededColumns []string, options *QueryOptions) ([]Row, error) {
	file, err := os.Open(s.filePath)
	if err != nil {
		return nil, err
	}
	defer file.Close()
	
	// è·å–æ–‡ä»¶å¤§å°
	fileInfo, err := file.Stat()
	if err != nil {
		return nil, err
	}
	fileSize := fileInfo.Size()
	
	// å¦‚æœæ–‡ä»¶å¾ˆå°,ç›´æ¥è¯»å–
	if fileSize < s.chunkSize {
		return s.readSequential(file, neededColumns, options)
	}
	
	// å¹¶è¡Œè¯»å–
	numChunks := int((fileSize + s.chunkSize - 1) / s.chunkSize)
	if numChunks > s.workers {
		numChunks = s.workers
	}
	
	var wg sync.WaitGroup
	results := make([][]Row, numChunks)
	errors := make([]error, numChunks)
	
	for i := 0; i < numChunks; i++ {
		wg.Add(1)
		go func(chunkIndex int) {
			defer wg.Done()
			
			offset := int64(chunkIndex) * s.chunkSize
			size := s.chunkSize
			if offset+size > fileSize {
				size = fileSize - offset
			}
			
			rows, err := s.readChunk(file, offset, size, neededColumns, options)
			if err != nil {
				errors[chunkIndex] = err
				return
			}
			results[chunkIndex] = rows
		}(i)
	}
	
	wg.Wait()
	
	// æ£€æŸ¥é”™è¯?
	for _, err := range errors {
		if err != nil {
			return nil, err
		}
	}
	
	// åˆå¹¶ç»“æœ
	totalRows := 0
	for _, result := range results {
		totalRows += len(result)
	}
	
	allRows := make([]Row, 0, totalRows)
	for _, result := range results {
		allRows = append(allRows, result...)
	}
	
	return allRows, nil
}

// readChunk è¯»å–æ–‡ä»¶çš„ä¸€ä¸ªchunk
func (s *CSVSource) readChunk(file *os.File, offset, size int64, neededColumns []string, options *QueryOptions) ([]Row, error) {
	// åˆ›å»ºCSVè¯»å–å™?
	reader := csv.NewReader(file)
	reader.Comma = s.delimiter
	
	// è·³è¿‡å¤´éƒ¨
	if s.header {
		if _, err := reader.Read(); err != nil {
			return nil, err
		}
	}
	
	var rows []Row
	for {
		record, err := reader.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			return nil, err
		}
		
		// è½¬æ¢ä¸ºRow
		row := s.parseRow(record)
		
		// åˆ—è£å‰?
		if len(neededColumns) > 0 {
			row = s.pruneRow(row, neededColumns)
		}
		
		// æ—©æœŸè¿‡æ»¤ - è¿‡æ»¤ä¸‹æ¨
		if s.matchesFilters(row, options) {
			rows = append(rows, row)
		}
	}
	
	return rows, nil
}

// readSequential é¡ºåºè¯»å–æ–‡ä»¶
func (s *CSVSource) readSequential(file *os.File, neededColumns []string, options *QueryOptions) ([]Row, error) {
	reader := csv.NewReader(file)
	reader.Comma = s.delimiter
	
	var rows []Row
	
	// è·³è¿‡å¤´éƒ¨
	if s.header {
		if _, err := reader.Read(); err != nil {
			return nil, err
		}
	}
	
	for {
		record, err := reader.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			return nil, err
		}
		
		// è½¬æ¢ä¸ºRow
		row := s.parseRow(record)
		
		// åˆ—è£å‰?
		if len(neededColumns) > 0 {
			row = s.pruneRow(row, neededColumns)
		}
		
		// æ—©æœŸè¿‡æ»¤
		if s.matchesFilters(row, options) {
			rows = append(rows, row)
		}
	}
	
	return rows, nil
}

// parseRow è§£æCSVè¡Œä¸ºRow
func (s *CSVSource) parseRow(record []string) Row {
	row := make(Row)
	
	for i, value := range record {
		if i >= len(s.columns) {
			break
		}
		
		colName := s.columns[i].Name
		colType := s.columns[i].Type
		
		parsedValue := s.parseValue(value, colType)
		row[colName] = parsedValue
	}
	
	return row
}

// parseValue è§£æå€?
func (s *CSVSource) parseValue(value string, colType string) interface{} {
	trimmed := strings.TrimSpace(value)
	if trimmed == "" {
		return nil
	}
	
	switch colType {
	case "INTEGER":
		if intVal, err := strconv.ParseInt(trimmed, 10, 64); err == nil {
			return intVal
		}
	case "FLOAT":
		if floatVal, err := strconv.ParseFloat(trimmed, 64); err == nil {
			return floatVal
		}
	case "BOOLEAN":
		if boolVal, err := strconv.ParseBool(trimmed); err == nil {
			return boolVal
		}
	}
	
	return trimmed
}

// getNeededColumns è·å–éœ€è¦è¯»å–çš„åˆ?
func (s *CSVSource) getNeededColumns(options *QueryOptions) []string {
	if options == nil {
		return nil
	}
	
	// ä»è¿‡æ»¤æ¡ä»¶ä¸­æå–éœ€è¦çš„åˆ?
	needed := make(map[string]bool)
	for _, filter := range options.Filters {
		needed[filter.Field] = true
	}
	
	// ä»æ’åºä¸­æå–
	if options.OrderBy != "" {
		needed[options.OrderBy] = true
	}
	
	if len(needed) == 0 {
		return nil
	}
	
	result := make([]string, 0, len(needed))
	for col := range needed {
		result = append(result, col)
	}
	
	return result
}

// pruneRow è£å‰ªè¡?åªä¿ç•™éœ€è¦çš„åˆ?
func (s *CSVSource) pruneRow(row Row, neededColumns []string) Row {
	if len(neededColumns) == 0 {
		return row
	}
	
	pruned := make(Row)
	for _, col := range neededColumns {
		if val, ok := row[col]; ok {
			pruned[col] = val
		}
	}
	return pruned
}

// filterColumns è¿‡æ»¤åˆ—ä¿¡æ?
func (s *CSVSource) filterColumns(neededColumns []string) []ColumnInfo {
	if len(neededColumns) == 0 {
		return s.columns
	}
	
	filtered := make([]ColumnInfo, 0, len(neededColumns))
	neededMap := make(map[string]bool)
	for _, col := range neededColumns {
		neededMap[col] = true
	}
	
	for _, col := range s.columns {
		if neededMap[col.Name] {
			filtered = append(filtered, col)
		}
	}
	
	return filtered
}

// matchesFilters æ—©æœŸè¿‡æ»¤æ£€æŸ?
func (s *CSVSource) matchesFilters(row Row, options *QueryOptions) bool {
	if options == nil || len(options.Filters) == 0 {
		return true
	}
	
	return s.matchesFiltersInternal(row, options.Filters)
}

// matchesFiltersInternal å†…éƒ¨è¿‡æ»¤æ£€æŸ?
func (s *CSVSource) matchesFiltersInternal(row Row, filters []Filter) bool {
	for _, filter := range filters {
		if !s.matchFilter(row, filter) {
			return false
		}
	}
	return true
}

// matchFilter å•ä¸ªè¿‡æ»¤å™¨åŒ¹é…?
func (s *CSVSource) matchFilter(row Row, filter Filter) bool {
	value, exists := row[filter.Field]
	if !exists {
		return false
	}
	
	switch filter.Operator {
	case "=":
		return s.compareEqual(value, filter.Value)
	case "!=":
		return !s.compareEqual(value, filter.Value)
	case ">":
		return s.compareGreater(value, filter.Value)
	case "<":
		return !s.compareGreater(value, filter.Value) && !s.compareEqual(value, filter.Value)
	case ">=":
		return s.compareGreater(value, filter.Value) || s.compareEqual(value, filter.Value)
	case "<=":
		return !s.compareGreater(value, filter.Value)
	default:
		return true
	}
}

// æ¯”è¾ƒè¾…åŠ©å‡½æ•°
func (s *CSVSource) compareEqual(a, b interface{}) bool {
	if cmp, ok := s.compareNumeric(a, b); ok {
		return cmp == 0
	}
	return fmt.Sprintf("%v", a) == fmt.Sprintf("%v", b)
}

func (s *CSVSource) compareGreater(a, b interface{}) bool {
	if cmp, ok := s.compareNumeric(a, b); ok {
		return cmp > 0
	}
	aStr := fmt.Sprintf("%v", a)
	bStr := fmt.Sprintf("%v", b)
	return aStr > bStr
}

func (s *CSVSource) compareNumeric(a, b interface{}) (int, bool) {
	aFloat, okA := s.toFloat64(a)
	bFloat, okB := s.toFloat64(b)
	if !okA || !okB {
		return 0, false
	}
	
	if aFloat < bFloat {
		return -1, true
	} else if aFloat > bFloat {
		return 1, true
	}
	return 0, true
}

func (s *CSVSource) toFloat64(v interface{}) (float64, bool) {
	switch val := v.(type) {
	case int:
		return float64(val), true
	case int64:
		return float64(val), true
	case float32:
		return float64(val), true
	case float64:
		return val, true
	default:
		return 0, false
	}
}

// applyFilters åº”ç”¨è¿‡æ»¤å™?
func (s *CSVSource) applyFilters(rows []Row, options *QueryOptions) []Row {
	if options == nil || len(options.Filters) == 0 {
		return rows
	}
	
	result := make([]Row, 0, len(rows))
	for _, row := range rows {
		if s.matchesFiltersInternal(row, options.Filters) {
			result = append(result, row)
		}
	}
	return result
}

// applyOrder åº”ç”¨æ’åº
func (s *CSVSource) applyOrder(rows []Row, options *QueryOptions) []Row {
	if options == nil || options.OrderBy == "" {
		return rows
	}
	
	// ç®€åŒ–å®ç? è¿”å›åŸå§‹é¡ºåº
	// å®é™…åº”è¯¥å®ç°å®Œæ•´çš„æ’åºé€»è¾‘
	return rows
}

// applyPagination åº”ç”¨åˆ†é¡µ
func (s *CSVSource) applyPagination(rows []Row, options *QueryOptions) []Row {
	if options == nil {
		return rows
	}
	return ApplyPagination(rows, options.Offset, options.Limit)
}

// åˆå§‹åŒ?
func init() {
	// æ³¨å†ŒCSVæ•°æ®æºç±»å?
	RegisterFactory(NewCSVFactory())
}
