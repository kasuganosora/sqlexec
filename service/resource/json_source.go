package resource

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"os"
	"sync"
)

// JSONSource JSONæ–‡ä»¶æ•°æ®æºå®ç?
type JSONSource struct {
	config      *DataSourceConfig
	connected   bool
	writable    bool // JSONæ–‡ä»¶é»˜è®¤åªè¯»
	mu          sync.RWMutex
	filePath    string
	columns     []ColumnInfo
	// å¹¶è¡Œè¯»å–é…ç½®
	chunkSize   int64
	workers     int
	// JSONæ ¼å¼
	arrayMode   bool // æ˜¯å¦ä¸ºæ•°ç»„æ ¼å¼?[ {}, {}, ... ]
	recordsPath string // JSONPath æŸ¥è¯¢è·¯å¾„
}

// JSONFactory JSONæ•°æ®æºå·¥å?
type JSONFactory struct{}

// NewJSONFactory åˆ›å»ºJSONæ•°æ®æºå·¥å?
func NewJSONFactory() *JSONFactory {
	return &JSONFactory{}
}

// GetType å®ç°DataSourceFactoryæ¥å£
func (f *JSONFactory) GetType() DataSourceType {
	return DataSourceTypeJSON
}

// Create å®ç°DataSourceFactoryæ¥å£
func (f *JSONFactory) Create(config *DataSourceConfig) (DataSource, error) {
	if config.Options == nil {
		config.Options = make(map[string]interface{})
	}
	
	chunkSize := int64(1 << 20) // 1MB
	if cs, ok := config.Options["chunk_size"]; ok {
		if num, ok := cs.(int64); ok && num > 0 {
			chunkSize = num
		}
	}
	
	workers := 4
	if w, ok := config.Options["workers"]; ok {
		if num, ok := w.(int); ok && num > 0 && num <= 32 {
			workers = num
		}
	}
	
	arrayMode := true
	if am, ok := config.Options["array_mode"]; ok {
		if b, ok := am.(bool); ok {
			arrayMode = b
		}
	}
	
	recordsPath := ""
	if rp, ok := config.Options["records_path"]; ok {
		if str, ok := rp.(string); ok {
			recordsPath = str
		}
	}

	return &JSONSource{
		config:      config,
		writable:    false, // JSONæ–‡ä»¶é»˜è®¤åªè¯»
		filePath:    config.Name,
		chunkSize:   chunkSize,
		workers:     workers,
		arrayMode:   arrayMode,
		recordsPath: recordsPath,
	}, nil
}

// Connect è¿æ¥æ•°æ®æº?
func (s *JSONSource) Connect(ctx context.Context) error {
	s.mu.Lock()
	defer s.mu.Unlock()
	
	// æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ?
	if _, err := os.Stat(s.filePath); err != nil {
		return fmt.Errorf("JSON file not found: %s", s.filePath)
	}
	
	// æ¨æ–­åˆ—ä¿¡æ?
	if err := s.inferSchema(ctx); err != nil {
		return fmt.Errorf("failed to infer schema: %w", err)
	}
	
	s.connected = true
	return nil
}

// Close å…³é—­è¿æ¥
func (s *JSONSource) Close(ctx context.Context) error {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.connected = false
	return nil
}

// IsConnected æ£€æŸ¥æ˜¯å¦å·²è¿æ¥
func (s *JSONSource) IsConnected() bool {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return s.connected
}

// GetConfig è·å–æ•°æ®æºé…ç½?
func (s *JSONSource) GetConfig() *DataSourceConfig {
	return s.config
}

// IsWritable æ£€æŸ¥æ˜¯å¦å¯å†?
func (s *JSONSource) IsWritable() bool {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return s.writable
}

// GetTables è·å–æ‰€æœ‰è¡¨
func (s *JSONSource) GetTables(ctx context.Context) ([]string, error) {
	if !s.IsConnected() {
		return nil, fmt.Errorf("not connected")
	}
	return []string{"json_data"}, nil
}

// GetTableInfo è·å–è¡¨ä¿¡æ?
func (s *JSONSource) GetTableInfo(ctx context.Context, tableName string) (*TableInfo, error) {
	if !s.IsConnected() {
		return nil, fmt.Errorf("not connected")
	}
	
	if tableName != "json_data" {
		return nil, fmt.Errorf("table %s not found", tableName)
	}
	
	return &TableInfo{
		Name:    "json_data",
		Columns: s.columns,
	}, nil
}

// Query æŸ¥è¯¢æ•°æ®
func (s *JSONSource) Query(ctx context.Context, tableName string, options *QueryOptions) (*QueryResult, error) {
	if !s.IsConnected() {
		return nil, fmt.Errorf("not connected")
	}
	
	if tableName != "json_data" {
		return nil, fmt.Errorf("table %s not found", tableName)
	}
	
	// è¯»å–æ•°æ®
	rows, err := s.readAll(ctx)
	if err != nil {
		return nil, err
	}
	
	// åº”ç”¨è¿‡æ»¤å™?
	filteredRows := s.applyFilters(rows, options)
	
	// åº”ç”¨æ’åº
	sortedRows := s.applyOrder(filteredRows, options)
	
	// åº”ç”¨åˆ†é¡µ
	total := int64(len(sortedRows))
	pagedRows := s.applyPagination(sortedRows, options)
	
	return &QueryResult{
		Columns: s.columns,
		Rows:    pagedRows,
		Total:   total,
	}, nil
}

// Insert æ’å…¥æ•°æ®
func (s *JSONSource) Insert(ctx context.Context, tableName string, rows []Row, options *InsertOptions) (int64, error) {
	return 0, fmt.Errorf("JSON data source is read-only")
}

// Update æ›´æ–°æ•°æ®
func (s *JSONSource) Update(ctx context.Context, tableName string, filters []Filter, updates Row, options *UpdateOptions) (int64, error) {
	return 0, fmt.Errorf("JSON data source is read-only")
}

// Delete åˆ é™¤æ•°æ®
func (s *JSONSource) Delete(ctx context.Context, tableName string, filters []Filter, options *DeleteOptions) (int64, error) {
	return 0, fmt.Errorf("JSON data source is read-only")
}

// CreateTable åˆ›å»ºè¡?
func (s *JSONSource) CreateTable(ctx context.Context, tableInfo *TableInfo) error {
	return fmt.Errorf("JSON data source is read-only")
}

// DropTable åˆ é™¤è¡?
func (s *JSONSource) DropTable(ctx context.Context, tableName string) error {
	return fmt.Errorf("JSON data source is read-only")
}

// TruncateTable æ¸…ç©ºè¡?
func (s *JSONSource) TruncateTable(ctx context.Context, tableName string) error {
	return fmt.Errorf("JSON data source is read-only")
}

// Execute æ‰§è¡Œè‡ªå®šä¹‰SQLè¯­å¥
func (s *JSONSource) Execute(ctx context.Context, sql string) (*QueryResult, error) {
	return nil, fmt.Errorf("JSON data source does not support SQL execution")
}

// inferSchema æ¨æ–­JSONæ–‡ä»¶çš„åˆ—ä¿¡æ¯
func (s *JSONSource) inferSchema(ctx context.Context) error {
	file, err := os.Open(s.filePath)
	if err != nil {
		return err
	}
	defer file.Close()
	
	// è¯»å–æ–‡ä»¶å†…å®¹
	data, err := io.ReadAll(file)
	if err != nil {
		return err
	}
	
	// è§£æJSON
	var records []map[string]interface{}
	if s.arrayMode {
		// æ•°ç»„æ ¼å¼: [ {}, {}, ... ]
		if err := json.Unmarshal(data, &records); err != nil {
			return fmt.Errorf("failed to parse JSON array: %w", err)
		}
	} else {
		// è¡Œåˆ†éš”æ ¼å¼? æ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡
		lines := splitLines(data)
		for _, line := range lines {
			var record map[string]interface{}
			if err := json.Unmarshal([]byte(line), &record); err != nil {
				continue
			}
			records = append(records, record)
		}
	}
	
	// é‡‡æ ·å‰?000è¡Œæ¨æ–­ç±»å?
	sampleSize := 1000
	if len(records) < sampleSize {
		sampleSize = len(records)
	}
	
	// æ”¶é›†æ‰€æœ‰å­—æ®?
	fieldsMap := make(map[string][]interface{})
	for i := 0; i < sampleSize; i++ {
		for key, value := range records[i] {
			fieldsMap[key] = append(fieldsMap[key], value)
		}
	}
	
	// æ¨æ–­æ¯åˆ—çš„ç±»å?
	s.columns = make([]ColumnInfo, 0, len(fieldsMap))
	for field, values := range fieldsMap {
		colType := s.inferColumnType(values)
		s.columns = append(s.columns, ColumnInfo{
			Name:     field,
			Type:     colType,
			Nullable: true,
			Primary:  false,
		})
	}
	
	return nil
}

// inferColumnType æ¨æ–­åˆ—ç±»å?
func (s *JSONSource) inferColumnType(values []interface{}) string {
	if len(values) == 0 {
		return "VARCHAR"
	}
	
	typeCounts := map[string]int{
		"INTEGER": 0,
		"FLOAT":   0,
		"BOOLEAN": 0,
		"VARCHAR": 0,
	}
	
	for _, value := range values {
		if value == nil {
			continue
		}
		
		colType := s.detectType(value)
		typeCounts[colType]++
	}
	
	// é€‰æ‹©æœ€å¸¸è§çš„ç±»å?
	maxCount := 0
	bestType := "VARCHAR"
	for t, count := range typeCounts {
		if count > maxCount {
			maxCount = count
			bestType = t
		}
	}
	
	return bestType
}

// detectType æ£€æµ‹å€¼çš„ç±»å‹
func (s *JSONSource) detectType(value interface{}) string {
	switch v := value.(type) {
	case bool:
		return "BOOLEAN"
	case float64:
		// JSONæ•°å­—é»˜è®¤ä¸ºfloat64,æ£€æŸ¥æ˜¯å¦ä¸ºæ•´æ•°
		if float64(int(v)) == v {
			return "INTEGER"
		}
		return "FLOAT"
	case int:
		return "INTEGER"
	case int64:
		return "INTEGER"
	case float32:
		return "FLOAT"
	case string:
		return "VARCHAR"
	default:
		return "VARCHAR"
	}
}

// readAll è¯»å–æ‰€æœ‰æ•°æ?
func (s *JSONSource) readAll(ctx context.Context) ([]Row, error) {
	file, err := os.Open(s.filePath)
	if err != nil {
		return nil, err
	}
	defer file.Close()
	
	var rows []Row
	
	if s.arrayMode {
		// æ•°ç»„æ ¼å¼
		data, err := io.ReadAll(file)
		if err != nil {
			return nil, err
		}
		
		var records []map[string]interface{}
		if err := json.Unmarshal(data, &records); err != nil {
			return nil, fmt.Errorf("failed to parse JSON: %w", err)
		}
		
		rows = make([]Row, len(records))
		for i, record := range records {
			rows[i] = Row(record)
		}
	} else {
		// è¡Œåˆ†éš”æ ¼å¼?
		decoder := json.NewDecoder(file)
		for {
			var record map[string]interface{}
			if err := decoder.Decode(&record); err == io.EOF {
				break
			} else if err != nil {
				continue
			}
			rows = append(rows, Row(record))
		}
	}
	
	return rows, nil
}

// applyFilters åº”ç”¨è¿‡æ»¤å™?
func (s *JSONSource) applyFilters(rows []Row, options *QueryOptions) []Row {
	if options == nil || len(options.Filters) == 0 {
		return rows
	}
	
	result := make([]Row, 0, len(rows))
	for _, row := range rows {
		if s.matchesFilters(row, options.Filters) {
			result = append(result, row)
		}
	}
	return result
}

// matchesFilters æ£€æŸ¥è¡Œæ˜¯å¦åŒ¹é…è¿‡æ»¤å™?
func (s *JSONSource) matchesFilters(row Row, filters []Filter) bool {
	for _, filter := range filters {
		if !s.matchFilter(row, filter) {
			return false
		}
	}
	return true
}

// matchFilter åŒ¹é…å•ä¸ªè¿‡æ»¤å™?
func (s *JSONSource) matchFilter(row Row, filter Filter) bool {
	value, exists := row[filter.Field]
	if !exists {
		return false
	}
	
	switch filter.Operator {
	case "=":
		return s.compareEqual(value, filter.Value)
	case "!=":
		return !s.compareEqual(value, filter.Value)
	case ">":
		return s.compareGreater(value, filter.Value)
	case "<":
		return !s.compareGreater(value, filter.Value) && !s.compareEqual(value, filter.Value)
	case ">=":
		return s.compareGreater(value, filter.Value) || s.compareEqual(value, filter.Value)
	case "<=":
		return !s.compareGreater(value, filter.Value)
	default:
		return true
	}
}

// æ¯”è¾ƒè¾…åŠ©å‡½æ•°
func (s *JSONSource) compareEqual(a, b interface{}) bool {
	if cmp, ok := s.compareNumeric(a, b); ok {
		return cmp == 0
	}
	return fmt.Sprintf("%v", a) == fmt.Sprintf("%v", b)
}

func (s *JSONSource) compareGreater(a, b interface{}) bool {
	if cmp, ok := s.compareNumeric(a, b); ok {
		return cmp > 0
	}
	aStr := fmt.Sprintf("%v", a)
	bStr := fmt.Sprintf("%v", b)
	return aStr > bStr
}

func (s *JSONSource) compareNumeric(a, b interface{}) (int, bool) {
	aFloat, okA := s.toFloat64(a)
	bFloat, okB := s.toFloat64(b)
	if !okA || !okB {
		return 0, false
	}
	
	if aFloat < bFloat {
		return -1, true
	} else if aFloat > bFloat {
		return 1, true
	}
	return 0, true
}

func (s *JSONSource) toFloat64(v interface{}) (float64, bool) {
	switch val := v.(type) {
	case int:
		return float64(val), true
	case int64:
		return float64(val), true
	case float32:
		return float64(val), true
	case float64:
		return val, true
	default:
		return 0, false
	}
}

// applyOrder åº”ç”¨æ’åº
func (s *JSONSource) applyOrder(rows []Row, options *QueryOptions) []Row {
	if options == nil || options.OrderBy == "" {
		return rows
	}
	
	// ç®€åŒ–å®ç? è¿”å›åŸå§‹é¡ºåº
	return rows
}

// applyPagination åº”ç”¨åˆ†é¡µ
func (s *JSONSource) applyPagination(rows []Row, options *QueryOptions) []Row {
	if options == nil {
		return rows
	}
	return ApplyPagination(rows, options.Offset, options.Limit)
}

// åˆå§‹åŒ?
func init() {
	RegisterFactory(NewJSONFactory())
}
