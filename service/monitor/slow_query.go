package monitor

import (
	"context"
	"fmt"
	"sync"
	"time"
)

// SlowQueryLog æ…¢æŸ¥è¯¢æ—¥å¿—é¡¹
type SlowQueryLog struct {
	ID          int64
	SQL         string
	Duration    time.Duration
	Timestamp   time.Time
	TableName   string
	RowCount    int64
	ExecutedBy  string
	Error       string
	ExplainPlan string
}

// SlowQueryAnalyzer æ…¢æŸ¥è¯¢åˆ†æå™¨
type SlowQueryAnalyzer struct {
	mu           sync.RWMutex
	slowQueries  []*SlowQueryLog
	slowQueryMap map[int64]*SlowQueryLog
	threshold    time.Duration
	maxEntries   int
	nextID       int64
}

// NewSlowQueryAnalyzer åˆ›å»ºæ…¢æŸ¥è¯¢åˆ†æå™¨
func NewSlowQueryAnalyzer(threshold time.Duration, maxEntries int) *SlowQueryAnalyzer {
	return &SlowQueryAnalyzer{
		slowQueries:  make([]*SlowQueryLog, 0, maxEntries),
		slowQueryMap: make(map[int64]*SlowQueryLog),
		threshold:    threshold,
		maxEntries:   maxEntries,
		nextID:       1,
	}
}

// IsSlowQuery æ£€æŸ¥æ˜¯å¦ä¸ºæ…¢æŸ¥è¯?
func (s *SlowQueryAnalyzer) IsSlowQuery(duration time.Duration) bool {
	return duration >= s.threshold
}

// RecordSlowQuery è®°å½•æ…¢æŸ¥è¯?
func (s *SlowQueryAnalyzer) RecordSlowQuery(sql string, duration time.Duration, tableName string, rowCount int64) int64 {
	if !s.IsSlowQuery(duration) {
		return 0
	}

	s.mu.Lock()
	defer s.mu.Unlock()

	log := &SlowQueryLog{
		ID:         s.nextID,
		SQL:        sql,
		Duration:   duration,
		Timestamp:  time.Now(),
		TableName:  tableName,
		RowCount:   rowCount,
		ExecutedBy: "system",
	}

	s.slowQueryMap[log.ID] = log
	s.slowQueries = append(s.slowQueries, log)
	s.nextID++

	// å¦‚æœè¶…å‡ºæœ€å¤§æ¡ç›®æ•°ï¼Œç§»é™¤æœ€æ—§çš„è®°å½•
	if len(s.slowQueries) > s.maxEntries {
		oldest := s.slowQueries[0]
		delete(s.slowQueryMap, oldest.ID)
		s.slowQueries = s.slowQueries[1:]
	}

	return log.ID
}

// RecordSlowQueryWithError è®°å½•å¸¦é”™è¯¯çš„æ…¢æŸ¥è¯?
func (s *SlowQueryAnalyzer) RecordSlowQueryWithError(sql string, duration time.Duration, tableName string, rowCount int64, err string) int64 {
	id := s.RecordSlowQuery(sql, duration, tableName, rowCount)
	if id > 0 {
		s.mu.Lock()
		defer s.mu.Unlock()
		if log, ok := s.slowQueryMap[id]; ok {
			log.Error = err
		}
	}
	return id
}

// GetSlowQuery è·å–æ…¢æŸ¥è¯¢è®°å½?
func (s *SlowQueryAnalyzer) GetSlowQuery(id int64) (*SlowQueryLog, bool) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	log, ok := s.slowQueryMap[id]
	return log, ok
}

// GetAllSlowQueries è·å–æ‰€æœ‰æ…¢æŸ¥è¯¢
func (s *SlowQueryAnalyzer) GetAllSlowQueries() []*SlowQueryLog {
	s.mu.RLock()
	defer s.mu.RUnlock()

	result := make([]*SlowQueryLog, len(s.slowQueries))
	copy(result, s.slowQueries)
	return result
}

// GetSlowQueriesByTable è·å–æŒ‡å®šè¡¨çš„æ…¢æŸ¥è¯?
func (s *SlowQueryAnalyzer) GetSlowQueriesByTable(tableName string) []*SlowQueryLog {
	s.mu.RLock()
	defer s.mu.RUnlock()

	result := []*SlowQueryLog{}
	for _, log := range s.slowQueries {
		if log.TableName == tableName {
			result = append(result, log)
		}
	}
	return result
}

// GetSlowQueriesByTimeRange è·å–æŒ‡å®šæ—¶é—´èŒƒå›´çš„æ…¢æŸ¥è¯¢
func (s *SlowQueryAnalyzer) GetSlowQueriesByTimeRange(start, end time.Time) []*SlowQueryLog {
	s.mu.RLock()
	defer s.mu.RUnlock()

	result := []*SlowQueryLog{}
	for _, log := range s.slowQueries {
		if log.Timestamp.After(start) && log.Timestamp.Before(end) {
			result = append(result, log)
		}
	}
	return result
}

// GetSlowQueriesAfter è·å–æŒ‡å®šæ—¶é—´ä¹‹åçš„æ…¢æŸ¥è¯¢
func (s *SlowQueryAnalyzer) GetSlowQueriesAfter(start time.Time) []*SlowQueryLog {
	return s.GetSlowQueriesByTimeRange(start, time.Now())
}

// GetSlowQueryCount è·å–æ…¢æŸ¥è¯¢æ€»æ•°
func (s *SlowQueryAnalyzer) GetSlowQueryCount() int {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return len(s.slowQueries)
}

// SetExplainPlan è®¾ç½®æ‰§è¡Œè®¡åˆ’
func (s *SlowQueryAnalyzer) SetExplainPlan(id int64, explainPlan string) {
	s.mu.Lock()
	defer s.mu.Unlock()

	if log, ok := s.slowQueryMap[id]; ok {
		log.ExplainPlan = explainPlan
	}
}

// DeleteSlowQuery åˆ é™¤æ…¢æŸ¥è¯¢è®°å½?
func (s *SlowQueryAnalyzer) DeleteSlowQuery(id int64) bool {
	s.mu.Lock()
	defer s.mu.Unlock()

	if _, ok := s.slowQueryMap[id]; !ok {
		return false
	}

	delete(s.slowQueryMap, id)
	for i, log := range s.slowQueries {
		if log.ID == id {
			s.slowQueries = append(s.slowQueries[:i], s.slowQueries[i+1:]...)
			break
		}
	}
	return true
}

// Clear æ¸…ç©ºæ‰€æœ‰æ…¢æŸ¥è¯¢
func (s *SlowQueryAnalyzer) Clear() {
	s.mu.Lock()
	defer s.mu.Unlock()

	s.slowQueries = make([]*SlowQueryLog, 0, s.maxEntries)
	s.slowQueryMap = make(map[int64]*SlowQueryLog)
	s.nextID = 1
}

// SetThreshold è®¾ç½®æ…¢æŸ¥è¯¢é˜ˆå€?
func (s *SlowQueryAnalyzer) SetThreshold(threshold time.Duration) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.threshold = threshold
}

// GetThreshold è·å–æ…¢æŸ¥è¯¢é˜ˆå€?
func (s *SlowQueryAnalyzer) GetThreshold() time.Duration {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return s.threshold
}

// AnalyzeSlowQueries åˆ†ææ…¢æŸ¥è¯?
func (s *SlowQueryAnalyzer) AnalyzeSlowQueries() *SlowQueryAnalysis {
	s.mu.RLock()
	defer s.mu.RUnlock()

	if len(s.slowQueries) == 0 {
		return &SlowQueryAnalysis{}
	}

	analysis := &SlowQueryAnalysis{
		TotalQueries:      len(s.slowQueries),
		TableStats:        make(map[string]*TableSlowQueryStats),
		ErrorCount:        0,
		AvgDuration:       0,
		MaxDuration:       s.slowQueries[0].Duration,
		MinDuration:       s.slowQueries[0].Duration,
		TotalDuration:     0,
		AvgRowCount:       0,
		TotalRowCount:     0,
	}

	totalDuration := time.Duration(0)
	totalRowCount := int64(0)

	for _, log := range s.slowQueries {
		totalDuration += log.Duration
		totalRowCount += log.RowCount

		if log.Duration > analysis.MaxDuration {
			analysis.MaxDuration = log.Duration
		}
		if log.Duration < analysis.MinDuration {
			analysis.MinDuration = log.Duration
		}

		if log.Error != "" {
			analysis.ErrorCount++
		}

		// è¡¨çº§åˆ«ç»Ÿè®?
		if stats, ok := analysis.TableStats[log.TableName]; ok {
			stats.QueryCount++
			stats.TotalDuration += log.Duration
			stats.TotalRowCount += log.RowCount
			if log.Duration > stats.MaxDuration {
				stats.MaxDuration = log.Duration
			}
		} else {
			analysis.TableStats[log.TableName] = &TableSlowQueryStats{
				TableName:     log.TableName,
				QueryCount:    1,
				TotalDuration: log.Duration,
				MaxDuration:   log.Duration,
				TotalRowCount: log.RowCount,
			}
		}
	}

	analysis.TotalDuration = totalDuration
	analysis.AvgDuration = totalDuration / time.Duration(len(s.slowQueries))
	analysis.TotalRowCount = totalRowCount
	if len(s.slowQueries) > 0 {
		analysis.AvgRowCount = totalRowCount / int64(len(s.slowQueries))
	}

	return analysis
}

// SlowQueryAnalysis æ…¢æŸ¥è¯¢åˆ†æç»“æ?
type SlowQueryAnalysis struct {
	TotalQueries   int
	AvgDuration    time.Duration
	MaxDuration    time.Duration
	MinDuration    time.Duration
	TotalDuration  time.Duration
	AvgRowCount    int64
	TotalRowCount  int64
	ErrorCount     int
	TableStats     map[string]*TableSlowQueryStats
}

// TableSlowQueryStats è¡¨çº§åˆ«æ…¢æŸ¥è¯¢ç»Ÿè®¡
type TableSlowQueryStats struct {
	TableName     string
	QueryCount    int
	TotalDuration time.Duration
	MaxDuration   time.Duration
	AvgDuration   time.Duration
	TotalRowCount int64
	AvgRowCount   int64
}

// GetRecommendations è·å–ä¼˜åŒ–å»ºè®®
func (s *SlowQueryAnalyzer) GetRecommendations() []string {
	analysis := s.AnalyzeSlowQueries()
	recommendations := []string{}

	// åŸºäºæ…¢æŸ¥è¯¢æ€»æ•°çš„å»ºè®?
	if analysis.TotalQueries > 100 {
		recommendations = append(recommendations, fmt.Sprintf("æ…¢æŸ¥è¯¢æ•°é‡è¿‡å¤?%d)ï¼Œå»ºè®®æ£€æŸ¥æŸ¥è¯¢ä¼˜åŒ–ç­–ç•?, analysis.TotalQueries))
	}

	// åŸºäºå¹³å‡æ—¶é•¿çš„å»ºè®?
	if analysis.AvgDuration > time.Second {
		recommendations = append(recommendations, fmt.Sprintf("å¹³å‡æŸ¥è¯¢æ—¶é•¿è¾ƒé•¿(%v)ï¼Œå»ºè®®æ·»åŠ ç´¢å¼•æˆ–ä¼˜åŒ–æŸ¥è¯¢è¯­å¥", analysis.AvgDuration))
	}

	// åŸºäºé”™è¯¯ç‡çš„å»ºè®®
	if analysis.TotalQueries > 0 {
		errorRate := float64(analysis.ErrorCount) / float64(analysis.TotalQueries)
		if errorRate > 0.1 {
			recommendations = append(recommendations, fmt.Sprintf("æ…¢æŸ¥è¯¢é”™è¯¯ç‡è¿‡é«˜(%.2f%%)ï¼Œå»ºè®®æ£€æŸ¥é”™è¯¯åŸå›?, errorRate*100))
		}
	}

	// è¡¨çº§åˆ«å»ºè®?
	for tableName, stats := range analysis.TableStats {
		if stats.QueryCount > 10 {
			recommendations = append(recommendations, fmt.Sprintf("è¡?%s æœ?%d æ¡æ…¢æŸ¥è¯¢ï¼Œå»ºè®®ä¼˜åŒ–è¯¥è¡¨çš„æŸ¥è¯¢", tableName, stats.QueryCount))
		}
		if stats.AvgDuration > time.Second*2 {
			recommendations = append(recommendations, fmt.Sprintf("è¡?%s çš„å¹³å‡æŸ¥è¯¢æ—¶é•¿è¾ƒé•?%v)ï¼Œå»ºè®®æ·»åŠ ç´¢å¼?, tableName, stats.AvgDuration))
		}
	}

	return recommendations
}

// MonitorContext ç›‘æ§ä¸Šä¸‹æ–?
type MonitorContext struct {
	Metrics      *MetricsCollector
	SlowQuery    *SlowQueryAnalyzer
	Ctx          context.Context
	QueryID      int64
	StartTime    time.Time
	TableName    string
}

// NewMonitorContext åˆ›å»ºç›‘æ§ä¸Šä¸‹æ–?
func NewMonitorContext(ctx context.Context, metrics *MetricsCollector, slowQuery *SlowQueryAnalyzer, sql string) *MonitorContext {
	return &MonitorContext{
		Metrics:   metrics,
		SlowQuery: slowQuery,
		Ctx:       ctx,
		StartTime: time.Now(),
	}
}

// Start å¼€å§‹ç›‘æ?
func (mc *MonitorContext) Start() {
	mc.Metrics.StartQuery()
}

// End ç»“æŸç›‘æ§
func (mc *MonitorContext) End(success bool, rowCount int64, err error) {
	duration := time.Since(mc.StartTime)
	mc.Metrics.RecordQuery(duration, success, mc.TableName)
	mc.Metrics.EndQuery()

	if mc.SlowQuery.IsSlowQuery(duration) {
		var errMsg string
		if err != nil {
			errMsg = err.Error()
		}
		mc.SlowQuery.RecordSlowQueryWithError("", duration, mc.TableName, rowCount, errMsg)
	}
}
